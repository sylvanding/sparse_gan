# Sparse GAN - 3Dä½“ç´ ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ

åŸºäº **MinkowskiEngine** å®ç°çš„ç¨€ç–å·ç§¯ GANï¼Œç”¨äºç”Ÿæˆ 3D åŒ»å­¦å½±åƒä½“ç´ æ•°æ®ã€‚

## ğŸŒŸ ç‰¹æ€§

- âœ¨ **ç¨€ç–å·ç§¯æ¶æ„**ï¼šä½¿ç”¨ MinkowskiEngine é«˜æ•ˆå¤„ç†ç¨€ç– 3D æ•°æ®
- ğŸ¯ **WGAN-GP è®­ç»ƒ**ï¼šç¨³å®šçš„ GAN è®­ç»ƒç­–ç•¥ï¼Œæ”¯æŒæ¢¯åº¦æƒ©ç½š
- ğŸ”„ **çµæ´»çš„æ•°æ®åŠ è½½**ï¼šé›†æˆ NIfTI æ•°æ®é›†ï¼Œè‡ªåŠ¨å¤„ç†å¯†é›†-ç¨€ç–è½¬æ¢
- ğŸ“Š **å¤šç§è¾“å‡ºæ ¼å¼**ï¼šæ”¯æŒ NIfTIã€NumPy æ ¼å¼è¾“å‡º
- ğŸ¨ **å¯è§†åŒ–å·¥å…·**ï¼šå†…ç½®åˆ‡ç‰‡å’Œ 3D å¯è§†åŒ–åŠŸèƒ½
- ğŸ”€ **æ½œåœ¨ç©ºé—´æ’å€¼**ï¼šæ”¯æŒçº¿æ€§å’Œçƒé¢çº¿æ€§æ’å€¼

## ğŸ“ æ–‡ä»¶ç»“æ„

```
sparse_gan/
â”œâ”€â”€ sparse_gan_config.yaml          # é…ç½®æ–‡ä»¶
â”œâ”€â”€ sparse_gan_models.py            # ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨æ¨¡å‹
â”œâ”€â”€ sparse_gan_dataset.py           # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
â”œâ”€â”€ sparse_gan_trainer.py           # è®­ç»ƒå™¨
â”œâ”€â”€ sparse_gan_sampling.py          # é‡‡æ ·å’Œå¯è§†åŒ–
â”œâ”€â”€ train_sparse_gan.py             # è®­ç»ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ sample_sparse_gan.py            # é‡‡æ ·å¯åŠ¨è„šæœ¬
â”œâ”€â”€ voxel_nifti_dataset.py          # NIfTIæ•°æ®é›†åŠ è½½å™¨
â””â”€â”€ README_SPARSE_GAN.md            # æœ¬æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

```bash
# å®‰è£… PyTorch (æ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬)
pip install torch torchvision

# å®‰è£… MinkowskiEngine
pip install MinkowskiEngine

# å®‰è£…å…¶ä»–ä¾èµ–
pip install monai nibabel pyyaml tensorboard tqdm matplotlib
```

### 2. å‡†å¤‡æ•°æ®

å°† NIfTI æ ¼å¼çš„ä½“ç´ æ•°æ®æ”¾å…¥è®­ç»ƒå’ŒéªŒè¯ç›®å½•ï¼š

```
/data/nifti/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ sample_001.nii.gz
â”‚   â”œâ”€â”€ sample_002.nii.gz
â”‚   â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ sample_101.nii.gz
    â””â”€â”€ ...
```

### 3. ä¿®æ”¹é…ç½®

ç¼–è¾‘ `sparse_gan_config.yaml`ï¼š

```yaml
data:
  train_data_dir: "/path/to/your/train"  # ä¿®æ”¹ä¸ºä½ çš„è®­ç»ƒæ•°æ®è·¯å¾„
  val_data_dir: "/path/to/your/val"      # ä¿®æ”¹ä¸ºä½ çš„éªŒè¯æ•°æ®è·¯å¾„
  voxel_size: 64                          # ä½“ç´ åˆ†è¾¨ç‡
```

### 4. å¼€å§‹è®­ç»ƒ

```bash
# åŸºæœ¬è®­ç»ƒ
python train_sparse_gan.py --config sparse_gan_config.yaml

# æŒ‡å®šå‚æ•°è®­ç»ƒ
python train_sparse_gan.py \
    --config sparse_gan_config.yaml \
    --train_data_dir /path/to/train \
    --batch_size 4 \
    --num_epochs 200

# æ¢å¤è®­ç»ƒ
python train_sparse_gan.py \
    --config sparse_gan_config.yaml \
    --resume checkpoints/sparse_gan/checkpoint_latest.pth
```

### 5. ç”Ÿæˆæ ·æœ¬

```bash
# éšæœºç”Ÿæˆ10ä¸ªæ ·æœ¬
python sample_sparse_gan.py \
    --checkpoint checkpoints/sparse_gan/checkpoint_best.pth \
    --num_samples 10 \
    --output_dir outputs/samples

# ç”Ÿæˆæ’å€¼åºåˆ—
python sample_sparse_gan.py \
    --checkpoint checkpoints/sparse_gan/checkpoint_best.pth \
    --interpolate \
    --num_steps 20 \
    --output_dir outputs/interpolation

# ç”Ÿæˆå¹¶å¯è§†åŒ–
python sample_sparse_gan.py \
    --checkpoint checkpoints/sparse_gan/checkpoint_best.pth \
    --num_samples 5 \
    --visualize \
    --format both
```

## ğŸ—ï¸ æ¨¡å‹æ¶æ„

### ç”Ÿæˆå™¨ (SparseGenerator)

```
æ½œåœ¨å‘é‡ (256D)
    â†“
å…¨è¿æ¥å±‚ â†’ åˆå§‹ç‰¹å¾ç½‘æ ¼ (4Ã—4Ã—4, 256é€šé“)
    â†“
ç¨€ç–è½¬ç½®å·ç§¯ â†‘2Ã— â†’ 8Ã—8Ã—8, 128é€šé“
    â†“
ç¨€ç–è½¬ç½®å·ç§¯ â†‘2Ã— â†’ 16Ã—16Ã—16, 64é€šé“
    â†“
ç¨€ç–è½¬ç½®å·ç§¯ â†‘2Ã— â†’ 32Ã—32Ã—32, 32é€šé“
    â†“
ç¨€ç–è½¬ç½®å·ç§¯ â†‘2Ã— â†’ 64Ã—64Ã—64, 16é€šé“
    â†“
è¾“å‡ºå·ç§¯ â†’ 64Ã—64Ã—64, 1é€šé“ (ç¨€ç–)
```

### åˆ¤åˆ«å™¨ (SparseDiscriminator)

```
è¾“å…¥ä½“ç´  (64Ã—64Ã—64, 1é€šé“, ç¨€ç–)
    â†“
ç¨€ç–å·ç§¯ â†“2Ã— â†’ 32Ã—32Ã—32, 16é€šé“
    â†“
ç¨€ç–å·ç§¯ â†“2Ã— â†’ 16Ã—16Ã—16, 32é€šé“
    â†“
ç¨€ç–å·ç§¯ â†“2Ã— â†’ 8Ã—8Ã—8, 64é€šé“
    â†“
ç¨€ç–å·ç§¯ â†“2Ã— â†’ 4Ã—4Ã—4, 128é€šé“
    â†“
ç¨€ç–å·ç§¯ â†“2Ã— â†’ 2Ã—2Ã—2, 256é€šé“
    â†“
å…¨å±€æ± åŒ– + å…¨è¿æ¥ â†’ çœŸ/å‡åˆ†æ•°
```

## âš™ï¸ é…ç½®è¯´æ˜

### GAN ç±»å‹

- `wgan-gp`ï¼šWasserstein GAN with Gradient Penaltyï¼ˆæ¨èï¼Œæœ€ç¨³å®šï¼‰
- `vanilla`ï¼šæ ‡å‡† GANï¼ˆBCE æŸå¤±ï¼‰
- `lsgan`ï¼šLeast Squares GAN

### å…³é”®å‚æ•°

```yaml
generator:
  latent_dim: 256              # æ½œåœ¨å‘é‡ç»´åº¦
  channels: [256, 128, 64, 32, 16]  # æ¯å±‚é€šé“æ•°
  initial_tensor_stride: 32    # åˆå§‹ç¨€ç–å¼ é‡æ­¥é•¿

discriminator:
  channels: [16, 32, 64, 128, 256]  # æ¯å±‚é€šé“æ•°

training:
  gan_type: "wgan-gp"          # GANç±»å‹
  n_critic: 5                   # åˆ¤åˆ«å™¨è®­ç»ƒé¢‘ç‡
  gradient_penalty_weight: 10.0 # æ¢¯åº¦æƒ©ç½šæƒé‡
  batch_size: 4                 # æ‰¹é‡å¤§å°
  num_epochs: 200               # è®­ç»ƒè½®æ•°
```

## ğŸ“Š è®­ç»ƒç›‘æ§

### TensorBoard

```bash
tensorboard --logdir logs/sparse_gan
```

æŸ¥çœ‹æŒ‡æ ‡ï¼š
- åˆ¤åˆ«å™¨æŸå¤± (`train/discriminator/d_loss`)
- ç”Ÿæˆå™¨æŸå¤± (`train/generator/g_loss`)
- Wassersteinè·ç¦» (`train/discriminator/wasserstein_distance`)
- æ¢¯åº¦æƒ©ç½š (`train/discriminator/gradient_penalty`)

### è¾“å‡ºç›®å½•ç»“æ„

```
outputs/sparse_gan/
â”œâ”€â”€ samples/                    # ç”Ÿæˆçš„æ ·æœ¬
â”‚   â”œâ”€â”€ epoch_10/
â”‚   â”œâ”€â”€ epoch_20/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ checkpoints/                # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ checkpoint_epoch_10.pth
â”‚   â”œâ”€â”€ checkpoint_latest.pth
â”‚   â””â”€â”€ checkpoint_best.pth
â””â”€â”€ logs/                       # TensorBoardæ—¥å¿—
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### Python API

```python
import torch
from sparse_gan_models import SparseGenerator, SparseDiscriminator
from sparse_gan_sampling import create_sampler_from_checkpoint

# åŠ è½½æ¨¡å‹
sampler = create_sampler_from_checkpoint('checkpoints/checkpoint_best.pth')

# éšæœºé‡‡æ ·
voxels = sampler.sample(num_samples=5)

# ä»ç§å­é‡‡æ ·ï¼ˆå¯å¤ç°ï¼‰
voxel = sampler.sample_from_seed(seed=42)

# æ½œåœ¨ç©ºé—´æ’å€¼
z1 = torch.randn(256)
z2 = torch.randn(256)
interp_voxels = sampler.interpolate(z1, z2, num_steps=10, method='slerp')

# ä¿å­˜ä¸º NIfTI
sampler.save_as_nifti(voxels[0], 'output.nii.gz')
```

### è‡ªå®šä¹‰æ•°æ®ç¨€ç–åŒ–

```python
from sparse_gan_dataset import dense_to_sparse

# å°†å¯†é›†ä½“ç´ è½¬æ¢ä¸ºç¨€ç–è¡¨ç¤º
coords, feats = dense_to_sparse(
    dense_voxel,
    threshold=0.1,      # ä½“ç´ å€¼é˜ˆå€¼
    min_voxels=100      # æœ€å°‘ä¿ç•™çš„ä½“ç´ æ•°
)
```

## ğŸ“ è®ºæ–‡å’Œå¼•ç”¨

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹å·¥ä½œï¼š

1. **MinkowskiEngine**
   - Choy et al. "4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks", CVPR 2019

2. **WGAN-GP**
   - Gulrajani et al. "Improved Training of Wasserstein GANs", NeurIPS 2017

3. **Sparse VAE**
   - MinkowskiEngine VAE ç¤ºä¾‹

## ğŸ› å¸¸è§é—®é¢˜

### Q: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³ï¼Ÿ

A: å°è¯•ï¼š
- å‡å° `batch_size`
- å‡å° `voxel_size`ï¼ˆåˆ†è¾¨ç‡ï¼‰
- å¢å¤§ `threshold`ï¼ˆæ›´ç¨€ç–ï¼‰

### Q: ç”Ÿæˆçš„ä½“ç´ è´¨é‡ä¸å¥½ï¼Ÿ

A: å°è¯•ï¼š
- å¢åŠ è®­ç»ƒè½®æ•°
- è°ƒæ•´ `n_critic`ï¼ˆåˆ¤åˆ«å™¨è®­ç»ƒé¢‘ç‡ï¼‰
- å°è¯•ä¸åŒçš„ GAN ç±»å‹
- æ£€æŸ¥æ•°æ®è´¨é‡å’Œé¢„å¤„ç†

### Q: è®­ç»ƒä¸ç¨³å®šï¼Ÿ

A: 
- ä½¿ç”¨ `wgan-gp`ï¼ˆæœ€ç¨³å®šï¼‰
- é™ä½å­¦ä¹ ç‡
- å¢å¤§ `gradient_penalty_weight`

## ğŸ“§ è”ç³»å’Œæ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š
- æäº¤ GitHub Issue
- æŸ¥çœ‹ MinkowskiEngine æ–‡æ¡£ï¼šhttps://github.com/NVIDIA/MinkowskiEngine

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT è®¸å¯è¯ã€‚

---

**Happy Generating! ğŸ‰**

